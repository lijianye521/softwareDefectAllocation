{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#caiye：看起来是先取了两份试一试\n",
    "data_files = ['../../data/data_by_ocean/Eclipse_raw/raw/0_summary_description.csv']\n",
    "labels_files = ['../../data/data_by_ocean/Eclipse_raw/raw/0_bug_id_date_who.csv']\n",
    "test_data_files = ['../../data/data_by_ocean/Eclipse_raw/raw/1_summary_description.csv']\n",
    "test_labels_files = ['../../data/data_by_ocean/Eclipse_raw/raw/1_bug_id_date_who.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这段Python代码定义了一个函数`clean_str(string)`，其目的是对输入的字符串进行清理和标准化处理，以便于后续的文本处理或自然语言处理（NLP）任务。这种处理通常在数据预处理阶段进行，特别是在处理文本数据时非常常见。下面是这个函数的一些主要操作和目的：\n",
    "\n",
    "1. 使用正则表达式删除所有非字母数字字符、逗号、感叹号、问号、单引号和圆括号以外的字符，并用空格替换这些符号，以保持文本中的基本标点和结构。\n",
    "\n",
    "2. 特定的缩写和所有权表达（如`'s`、`'ve`、`n't`、`'re`、`'d`、`'ll`）被修改，使之与前面的单词之间有一个空格，以便于分词（Tokenization）。\n",
    "\n",
    "3. 逗号、感叹号、圆括号和问号前后被加上空格，以确保分词时这些标点符号能被正确分离。\n",
    "\n",
    "4. 连续的空白符（包括空格、制表符等）被替换为单个空格，这是为了去除不必要的空白字符，并统一空白符的表示。\n",
    "\n",
    "5. 最后，将字符串转换为小写，以去除大小写的影响，保证词语的一致性。\n",
    "\n",
    "这些步骤共同作用，使得输入的字符串被清理和标准化，去除了多余的空格和非基本的符号，保留了文本数据中的基本结构和重要信息，同时也为之后的文本分析、特征提取等步骤做好了准备。通过这样的处理，可以提高文本处理任务的效率和效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for data_file in data_files:\n",
    "    with open(data_file, 'r', encoding='latin-1') as f:\n",
    "        data.extend([s.strip() for s in f.readlines()])\n",
    "        data = [clean_str(s) for s in data]\n",
    "test_data = []\n",
    "for test_data_file in test_data_files:\n",
    "    with open(test_data_file, 'r', encoding='latin-1') as f:\n",
    "        test_data.extend([s.strip() for s in f.readlines()])\n",
    "        test_data = [clean_str(s) for s in test_data]\n",
    "\n",
    "labels = pd.read_csv(labels_files[0])\n",
    "labels_files.pop(0)\n",
    "for labels_file in labels_files:\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    labels.append(labels_df)\n",
    "\n",
    "test_labels = pd.read_csv(test_labels_files[0])\n",
    "test_labels_files.pop(0)\n",
    "for test_labels_file in test_labels_files:\n",
    "    test_labels_df = pd.read_csv(test_labels_file)\n",
    "    test_labels.append(test_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这段代码\n",
    "处理文本数据\n",
    "初始化数据列表：data和test_data列表被初始化为空，用于存储训练数据和测试数据。\n",
    "\n",
    "读取和清理训练数据：对于data_files列表中的每个文件路径，使用open函数以只读模式打开文件，指定'latin-1'编码。然后，读取文件的每一行，去除首尾空格（strip()），并将这些处理过的行添加到data列表中。之后，对data列表中的每个字符串应用clean_str函数进行进一步的文本清理。\n",
    "\n",
    "读取和清理测试数据：这个过程与处理训练数据相似，只是操作对象变为了test_data_files列表中的文件路径，处理后的数据存储在test_data列表中。\n",
    "\n",
    "处理标签数据\n",
    "初始化标签DataFrame：使用pandas的read_csv函数读取labels_files列表中的第一个文件，并将其存储为DataFrame对象labels。此后，第一个文件路径从labels_files列表中移除（pop(0)）。\n",
    "\n",
    "追加额外的标签数据：遍历剩余的labels_files中的每个文件路径，同样使用read_csv读取数据，然后将读取的DataFrame对象labels_df追加到labelsDataFrame对象中。\n",
    "\n",
    "处理测试标签数据：这个过程与处理训练标签数据相似，只是操作对象变为了test_labels_files列表中的文件路径，处理后的数据存储在test_labelsDataFrame中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dcr javadoc code assist should offer better support for closing tags \\\\( 1gkq0im \\\\) reply description dani megert 2001 10 10 23 07 46 edt when you want to write e g code test code you can not simple do the following 1 code assist , select code 2 type test 3 code assist , select code note at this point the content assist is empty does not come up , i have to enter a space first suggestions a \\\\) could offer code code as template \\\\( at 1 \\\\) b \\\\) go back on the line and search for nearest tag and offer its closing version i e if x is found then show the corresponding closing tag \\\\( if any \\\\) notes eg \\\\( 10 1 2001 12 04 43 am \\\\) templates support in the java doc partition should offer macros for code code etc reply comment 1 claude knaus 2001 10 11 04 06 30 edt suggestion a \\\\) has been implemented using templates the selection of the template happens via code assist add comment collapse all comments expand all comments , dcr javadoc code assist should offer better support for closing tags \\\\( 1gkq0im \\\\)',\n",
       " 'test reply description jerome lanneluc 2001 10 11 04 37 42 edt testing testing 1 , 2 , 3 reply comment 1 jerome lanneluc 2001 10 11 04 56 34 edt fixed add comment collapse all comments expand all comments , test']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_length = [len(x.split(\" \")) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_l = pd.DataFrame(document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>384.844326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>689.147453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49088.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  18179.000000\n",
       "mean     384.844326\n",
       "std      689.147453\n",
       "min       37.000000\n",
       "25%      133.000000\n",
       "50%      219.000000\n",
       "75%      424.000000\n",
       "max    49088.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_l.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18179, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document_l = pd.DataFrame([len(x.split(\" \")) for x in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>485.634523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>782.676791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25446.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  18179.000000\n",
       "mean     485.634523\n",
       "std      782.676791\n",
       "min       43.000000\n",
       "25%      156.000000\n",
       "50%      264.000000\n",
       "75%      523.000000\n",
       "max    25446.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_document_l.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:455: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:456: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:457: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\ProgramData\\anaconda3\\envs\\bug\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = vocabulary_processor.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_l_train = np.array(list(t_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159968, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_l_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ed=np.expand_dims(t_l_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159968,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(t_ed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2643"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_processor.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2272"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
